from painel_pisa.utils.conexao_mongo import conectar_mongo
from painel_pisa.utils.config import CONFIG
from pymongo import MongoClient
from transformers import pipeline
import torch

# Conex√£o com MongoDB
client = conectar_mongo(nome_banco="saeb")[1]
db = client["pisa"]
colecao_origem = db["relatorio_inep_pisa_2000_v2"]
colecao_destino = db["relatorio_inep_pisa_2000_analise_v2"]

# Carregar modelo BERT zero-shot
classifier = pipeline("zero-shot-classification", model="facebooos.path.join(k, "b")art-large-mnli", device=0 if torch.cuda.is_available() else -1)

# R√≥tulos educacionais (poder√£o ser expandidos)
labels = ["Cr√≠tica √† qualidade das escolas", "Desempenho por n√≠vel socioecon√¥mico", "Compara√ß√£o internacional", "Sugest√µes de pol√≠tica p√∫blica"]

# Limpar cole√ß√£o destino
colecao_destino.drop()

# Processar cada se√ß√£o
documento = colecao_origem.find_one({"ano": 2000})
total_paragrafos = 0
total_armazenados = 0

for secao in documento.get("secoes", []):
    nome_secao = secao.get("secao", "Sem t√≠tulo")
    for i, elemento in enumerate(secao.get("elementos", [])):
        if elemento.get("tipo") == "texto":
            texto = elemento.get("conteudo", "").strip()
            if not texto:
                continue
            total_paragrafos += 1
            print(f"  üìÑ [{total_paragrafos}] Par√°grafo {i + 1}: {texto[:60].replace(chr(10), ' ')}...")

            resultado = classifier(texto, labels, multi_label=True)
            analise = {
                "ano": 2000,
                "secao": nome_secao,
                "paragrafo": i,
                "texto_original": texto,
                "classificacao": dict(zip(resultado["labels"], resultado["scores"]))
            }
            colecao_destino.insert_one(analise)
            total_armazenados += 1

# Fechar conex√£o
client.close()

print("\n‚úÖ An√°lise conclu√≠da.")
print(f"üìä Total de par√°grafos processados: {total_paragrafos}")
print(f"üìÅ Total de an√°lises armazenadas: {total_armazenados}")

